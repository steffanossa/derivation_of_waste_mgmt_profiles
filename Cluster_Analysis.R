# 3 Cluster Analysis -----------------------------------------------------------
# Nutzen Sie Ihre neuen Dimensionen als Basis, um mit Hilfe einer Clusteranalyse
# Profile der Gemeinden herzuleiten. Sie sollten nicht mehr als zehn Profile
# herausarbeiten. Kennzeichnen Sie ihre endgültige Lösung.
#------------------------------------------------------------------------------'
## Hopkins statistic =========================================================== 
#' Hopkins statistic is used to assess the clustering tendency of a data set by
#' measuring the probability that a given data set is generated by a uniform
#' data distribution.
#' A value above .75 indicates a clustering tendency at 90% conf level
#' https://www.datanovia.com/en/lessons/assessing-clustering-tendency/
wm_df_transformed_pca %>% get_clust_tendency(n = nrow(wm_df_transformed_pca) - 1,
                                             graph = F)
#' .7793498. Quite good actually.

## Amount of Clusters ==========================================================
wm_df_transformed_pca %>%  fviz_nbclust(hcut, method = wss)


## Hierarchical Clustering =====================================================
### Agglomerative Methods ######################################################
#' Starting with a single observation, successively adding more.
#' There is are numbers of different methods for both, creating a distance matrix
#' and creating the clusters.
dist_meth <- c("euclidean",
               "maximum",
               "manhattan",
               "canberra",
               "minkowski")

daisy_meth <- c("euclidean",
                "manhattan",
                "gower")

hclust_meth <- c("single",
                 "complete",
                 "average",
                 "mcquitty",
                 "median",
                 "centroid",
                 "ward")

pdf("figs/dendro_dist_hclust.pdf", width = 16, height = 9)
for (dm in dist_meth) {
  for (cm in hclust_meth) {
    hdist <- dist(scale(wm_df_transformed_pca),
                  dm)
    hcl <- flashClust::flashClust(hdist, cm)
    plot(hcl,
         main = paste0("dist method: ", dm,
                       "\nclust method: ", cm),
         sub = NA,
         labels = FALSE)
  }
}
dev.off()

pdf("figs/dendro_daisy.pdf", width = 16, height = 9)
for (dm in daisy_meth) {
  for (cm in hclust_meth) {
    daisydist <- daisy(wm_df_transformed_pca,
                       metric = dm,
                       stand = TRUE)
    flashClust::flashClust(daisydist, cm) %>% 
      plot(main = paste0("dist method: ", dm,
                         "\nclust method: ", cm),
           sub = NA,
           labels = FALSE)
  }
}
dev.off()
#' Canberra + ward.D2 looks best.
hclust_a <- 
  dist(scale(wm_df_transformed_pca), 
       method = "canberra") %>% 
  hclust(method = "ward.D2")
ggdendrogram(hclustt, leaf_labels = F, labels = F) +
  labs(title = paste0("Distance: canberra", "\nCluster: ward.D2"))

#### Profiling using Microsoft Excel ###########################################
for (i in 2:6) {
  wm_df_prepped_clust_a <-
    wm_df_prepped %>%
    mutate(Cluster_a = cutree(hclust_a, k = i))
  
  profiling_df <-
    wm_df_prepped_clust_a %>% 
    group_by(Cluster_a) %>% 
    summarize_all(mean)
  profiling_df$n_Cluster <- i
  profiling_df$Size <- table(wm_df_prepped_clust_a$Cluster_a)
  
  if (i == 2) {
    profiling_df_final <- profiling_df
  } else {
    profiling_df_final <-
      profiling_df_final %>% 
      rows_append(profiling_df)
  }
}

write.csv2(profiling_df_final, file = "profiling_clust_a.csv")

### Divisive Methods ###########################################################
#' Starting with a single cluster containing all observations, splitting up more
#' and more.
#### Diana (DIvisive, ANAlysis Clustering) #####################################

**...**


#### Mona (MONothetic Analysis) ################################################
## Partiotional Clustering =====================================================
### K-Means ####################################################################
#' Optimal number of clusters using withinSS
fviz_nbclust(wm_df_transformed_pca, kmeans, method = "wss")
#' 3
fviz_nbclust(wm_df_transformed_pca, kmeans, method = "silhouette")
#' 3
fviz_nbclust(wm_df_transformed_pca, kmeans, method = "gap_stat")
#' 9. No.
kmeans(wm_df_transformed_pca, centers = 3, iter.max = 10, nstart = 10)

#### Profiling using Microsoft Excel ###########################################
for (i in 2:5) {
  kmeans_t <- kmeans(scale(wm_df_transformed_pca),
                   centers = i,
                   nstart = 10,
                   iter.max = 10
                   )
  
  wm_df_prepped_clust_kmeans <-
    wm_df_prepped %>% 
    mutate(Cluster_k = kmeans_t$cluster)
  
  profiling_df_kmeans <-
    wm_df_prepped_clust_kmeans %>% 
    group_by(Cluster_k) %>% 
    summarise_all(mean)
  
  profiling_df_kmeans$n_Cluster <- i
  profiling_df_kmeans$Size <- table(wm_df_prepped_clust_kmeans$Cluster_k)
  
  if (i == 2) {
    profiling_df_kmeans_final <- profiling_df_kmeans
  } else {
    profiling_df_kmeans_final <-
      profiling_df_kmeans_final %>% 
      rows_append(profilings_df)
  }
}

write.csv2(profiling_df_kmeans_final, file = "profiling_kmeans.csv")

#' Decided to go with dist + hclust cannerra&ward.D2 after inspection in Excel
